# -*- coding: utf-8 -*-
"""Concurrency Best Practices for Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xvaXUbXQEvTOJKpXJb8o3sOiotPJI4XJ
"""

# FULL CODE FOR GOOGLE COLAB (PLAIN TEXT VERSION)
# Run this in Google Colab after installing dependencies
# !pip install nest_asyncio aiohttp

import asyncio
import time
import concurrent.futures
import aiohttp
import nest_asyncio

# Apply patch for nested event loops in Colab.  This is essential for
# running asyncio within the Colab environment, which already has an
# event loop running.
nest_asyncio.apply()

# ASYNC I/O EXAMPLE (URL FETCHING)
async def fetch_url_async(session, url):
    """
    Fetch content from a URL asynchronously using aiohttp.

    Args:
        session (aiohttp.ClientSession): The aiohttp session to use.  Passing
            the session is more efficient for multiple requests.
        url (str): The URL to fetch.

    Returns:
        str: The text content of the URL, or None on error.
    """
    try:
        async with session.get(url) as response:
            # Read the response text.  Use .text() for text, .read() for bytes.
            text = await response.text()
            print(f"Asyncio: Received {len(text)} bytes from {url}")
            return text
    except Exception as e:
        print(f"Asyncio: Error fetching {url}: {e}")
        return None


async def main_asyncio():
    """
    Main async function to demonstrate I/O-bound task with two URLs.
    This function now fetches two URLs concurrently.
    """
    urls = [
        "https://www.example.com",  # A very simple, reliable website.
        "https://www.python.org",  # Another simple, reliable website.
    ]
    print(f"Asyncio: Fetching URLs: {urls}")

    # Create a single aiohttp session for both requests.  This is the
    # recommended way to use aiohttp for multiple requests.
    async with aiohttp.ClientSession() as session:
        # Create a list of tasks.  Each task is a call to fetch_url_async
        # with the session and the corresponding URL.
        tasks = [
            fetch_url_async(session, url) for url in urls
        ]
        # Use asyncio.gather to run the tasks concurrently and get the results
        results = await asyncio.gather(*tasks)

    # Process the results.  In this case, we just print a message.  In a
    # real application, you would do something more useful with the data.
    for i, result in enumerate(results):
        if result:
            print(f"Asyncio: Successfully fetched data from {urls[i]}")
        else:
            print(f"Asyncio: Failed to fetch data from {urls[i]}")



# CPU-BOUND EXAMPLE (SQUARE CALCULATION)
def calculate_square(number):
    """
    Calculate square of a number (CPU-bound task).

    Args:
        number (int): The number to square.

    Returns:
        int: The square of the number.
    """
    print(f"Concurrent.futures: Calculating square of {number} in a separate process...")
    return number * number



def main_cpu():
    """
    Main function to demonstrate CPU-bound task.
    This function calculates the square of a number using concurrent.futures
    """
    number = 5
    with concurrent.futures.ProcessPoolExecutor() as executor:
        future = executor.submit(calculate_square, number)
        result = future.result()  # Get the result of the calculation.
        print(f"Concurrent.futures: The square of {number} is {result}")



# RUN BOTH EXAMPLES
if __name__ == "__main__":
    # Async I/O Example
    print("Running asyncio example:")
    loop = asyncio.get_event_loop()  # Get existing Colab event loop
    loop.run_until_complete(main_asyncio())  # Run async function

    # CPU-Bound Example
    print("\nRunning concurrent.futures example:")
    main_cpu()  # Run the CPU-bound example.