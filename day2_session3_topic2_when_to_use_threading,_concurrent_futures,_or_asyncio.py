# -*- coding: utf-8 -*-
"""When to Use Threading, concurrent.futures, or asyncio

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hWYtZir_nqXAQIL5XCLIGFjFzXemaIdd
"""

"""
Day 3, Session 3, Topic 2: When to Use Threading, concurrent.futures, or asyncio

This file explains the differences between threading, concurrent.futures, and
asyncio, and provides guidelines on when to use each for concurrent programming
in Python.
"""

import threading
import multiprocessing
import concurrent.futures
import asyncio
import time
import requests  # For I/O-bound examples

# -----------------------------------------------------------------------------
# Threading
# -----------------------------------------------------------------------------
#
# Threading allows you to run multiple threads within a single process.
# Threads share the same memory space, which can make communication between
# them easier but also requires careful handling of shared resources to
# avoid race conditions.
#
# When to Use Threading:
#
# -   I/O-bound tasks: Threading is most suitable for I/O-bound tasks, where
#     the program spends most of its time waiting for external operations
#     to complete, such as:
#     -   Network requests (downloading files, making API calls)
#     -   Reading from/writing to files
#     -   Waiting for user input
#
#     While the GIL can limit CPU-bound parallelism, it has minimal impact
#     on I/O-bound tasks because threads spend most of their time waiting
#     for I/O operations to complete, during which the GIL is released.
#
# -   Simple concurrency: Threading can be easier to understand and use
#     for simple concurrency needs compared to asyncio, especially for
#     programmers who are new to asynchronous programming.
#
# How to Manage Threads:
#
# -   `threading.Thread`:  The basic class for creating and managing threads.
# -   `threading.Lock`, `threading.RLock`, `threading.Semaphore`,
#     `threading.Condition`:  Synchronization primitives for controlling
#     access to shared resources and preventing race conditions.
# -   `concurrent.futures.ThreadPoolExecutor`:  A higher-level interface
#     for managing a pool of threads.
#
# Example: Threading for I/O-bound task (downloading files)
def download_file_thread(url, filename):
    """
    Downloads a file from a URL using threads.

    Args:
        url: The URL of the file to download.
        filename: The name of the file to save.
    """
    print(f"Thread {threading.current_thread().name}: Downloading {url} to {filename}")
    try:
        response = requests.get(url, stream=True)
        response.raise_for_status()  # Raise an exception for bad status codes
        with open(filename, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        print(f"Thread {threading.current_thread().name}: Download of {filename} complete")
    except requests.exceptions.RequestException as e:
        print(f"Thread {threading.current_thread().name}: Error downloading {url}: {e}")
    except Exception as e:
        print(f"Thread {threading.current_thread().name}: An error occurred: {e}")

def demonstrate_threading_io():
    """
    Demonstrates using threads for an I/O-bound task (downloading files).
    """
    start_time = time.time()
    threads = []
    urls = [
        "https://www.google.com",
        "https://www.github.com",
        "https://www.example.com",
        "https://www.python.org"
    ]
    for i, url in enumerate(urls):
        thread = threading.Thread(target=download_file_thread, args=(url, f"file_{i}.html"))
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

    end_time = time.time()
    print(f"Threading (I/O-bound) time: {end_time - start_time:.4f} seconds")
    # Cleanup the downloaded files
    import os
    for i in range(len(urls)):
        try:
            os.remove(f"file_{i}.html")
        except OSError:
            pass
# -----------------------------------------------------------------------------
# concurrent.futures
# -----------------------------------------------------------------------------
#
# The `concurrent.futures` module provides a high-level interface for working
# with both threads and processes.  It simplifies the process of submitting
# tasks to a pool of threads or processes and retrieving the results.
#
# When to Use concurrent.futures:
#
# -   Simplified concurrency:  `concurrent.futures` provides a more convenient
#     way to manage threads or processes compared to using the `threading`
#     or `multiprocessing` modules directly.
#
# -   Abstraction over threads and processes:  You can use the same interface
#     (`ThreadPoolExecutor` or `ProcessPoolExecutor`) to execute tasks
#     concurrently, regardless of whether they are I/O-bound or CPU-bound.
#     This allows you to easily switch between threads and processes
#     depending on your needs.
#
# -   Heterogeneous tasks:  `concurrent.futures` is well-suited for scenarios
#     where you have a mix of I/O-bound and CPU-bound tasks.  You can use
#     a `ThreadPoolExecutor` for the I/O-bound tasks and a
#     `ProcessPoolExecutor` for the CPU-bound tasks.
#
# How to Use concurrent.futures:
#
# -   `ThreadPoolExecutor`:  Creates a pool of threads.
# -   `ProcessPoolExecutor`:  Creates a pool of processes.
# -   `submit(func, *args, **kwargs)`:  Submits a function to the executor
#     and returns a `Future` object representing the result.
# -   `as_completed(futures)`:  An iterator that yields `Future` objects
#     as they complete.
# -   `wait(futures)`:  Waits for the `Future` objects to complete.
# -   `Future.result()`:  Retrieves the result of a completed `Future`.
#
# Example: concurrent.futures for mixed tasks
def cpu_bound_task_cf(n):
    """
    A CPU-bound task.
    """
    result = 0
    for i in range(n):
        result += i * i
    return result

def io_bound_task_cf(url):
    """
    An I/O-bound task (downloading a file, simplified).

    Args:
      url: the url to "download"
    """
    print(f"Thread {threading.current_thread().name}: fetching {url}")
    try:
        response = requests.get(url)
        response.raise_for_status()
        return f"Downloaded {url} ({len(response.content)} bytes)"
    except requests.exceptions.RequestException as e:
        return f"Error downloading {url}: {e}"

def demonstrate_concurrent_futures():
    """
    Demonstrates using concurrent.futures for a mix of I/O-bound and CPU-bound tasks.
    """
    start_time = time.time()
    cpu_tasks = [
        (cpu_bound_task_cf, 5000000),
        (cpu_bound_task_cf, 7000000),
        (cpu_bound_task_cf, 6000000),
    ]
    io_tasks = [
        ("https://www.google.com"),
        ("https://www.github.com"),
        ("https://www.example.com"),
    ]

    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as io_executor, \
            concurrent.futures.ProcessPoolExecutor(max_workers=2) as cpu_executor:
        # Submit I/O-bound tasks to ThreadPoolExecutor
        io_futures = [io_executor.submit(io_bound_task_cf, url) for url in io_tasks]
        # Submit CPU-bound tasks to ProcessPoolExecutor
        cpu_futures = [cpu_executor.submit(cpu_task[0], cpu_task[1]) for cpu_task in cpu_tasks]

        # Wait for and retrieve results as they complete
        for future in concurrent.futures.as_completed(io_futures + cpu_futures):
            try:
                result = future.result()
                print(f"Result: {result}")
            except Exception as e:
                print(f"Exception: {e}")
    end_time = time.time()
    print(f"Concurrent.futures time: {end_time - start_time:.4f} seconds")
# -----------------------------------------------------------------------------
# asyncio
# -----------------------------------------------------------------------------
#
# `asyncio` is a library for writing concurrent code using asynchronous
# programming.  It uses a single-threaded event loop to manage the execution
# of multiple coroutines.
#
# Key Concepts:
#
# -   Event loop: The core of `asyncio`.  It is a single-threaded loop that
#     monitors events (e.g., I/O operations, timers) and schedules the
#     execution of coroutines based on those events.
#
# -   Coroutines:  Special functions declared with `async def` that can
#     suspend their execution and yield control back to the event loop.
#     Coroutines can later be resumed at the point where they were suspended.
#
# -   `await`:  A keyword used within a coroutine to suspend its execution
#     until an asynchronous operation completes.  When an `await` is
#     encountered, the coroutine yields control back to the event loop,
#     which can then execute other coroutines.
#
# When to Use asyncio:
#
# -   I/O-bound tasks:  Like threading, `asyncio` is well-suited for I/O-bound
#     tasks.  However, `asyncio` often provides better performance and
#     scalability for highly concurrent I/O operations compared to threading,
#     especially when dealing with a large number of connections or requests.
#
# -   Single-threaded concurrency:  `asyncio` achieves concurrency within a
#     single thread. This can simplify some aspects of programming, as you
#     don't have to worry about managing locks and shared memory in the same
#     way as with threading.
#
# -   Modern, asynchronous libraries:  Many modern Python libraries (e.g.,
#     aiohttp, asyncpg) provide asynchronous interfaces that are designed
#     to work efficiently with `asyncio`.
#
# How asyncio Works (Simplified):
#
# 1.  The event loop starts running.
# 2.  Coroutines are created and scheduled to run on the event loop.
# 3.  When a coroutine encounters an `await` expression, it suspends its
#     execution and yields control back to the event loop.
# 4.  The event loop checks for completed I/O operations or other events.
# 5.  When an event occurs, the event loop resumes the corresponding
#     coroutine at the point where it was suspended.
# 6.  Steps 3-5 repeat until all coroutines have completed.
# 7.  The event loop stops.
#
# Example: asyncio for I/O-bound task (downloading files)
async def download_file_async(url, filename):
    """
    Downloads a file from a URL using asyncio and aiohttp.

    Args:
        url: The URL of the file to download.
        filename: The name of the file to save.
    """
    import aiohttp  # Import aiohttp within the coroutine
    print(f"Coroutine: Downloading {url} to {filename}")
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                response.raise_for_status()
                with open(filename, 'wb') as f:
                    while True:
                        chunk = await response.content.readany()
                        if not chunk:
                            break
                        f.write(chunk)
                print(f"Coroutine: Download of {filename} complete")
    except aiohttp.ClientError as e:
        print(f"Coroutine: Error downloading {url}: {e}")
    except Exception as e:
        print(f"Coroutine: An error occurred: {e}")

async def demonstrate_asyncio_io():
    """
    Demonstrates using asyncio for an I/O-bound task (downloading files).
    """
    start_time = time.time()
    tasks = []
    urls = [
        "https://www.google.com",
        "https://www.github.com",
        "https://www.example.com",
        "https://www.python.org"
    ]
    for i, url in enumerate(urls):
        task = asyncio.create_task(download_file_async(url, f"file_async_{i}.html"))
        tasks.append(task)

    await asyncio.gather(*tasks)  # Run all downloads concurrently

    end_time = time.time()
    print(f"asyncio (I/O-bound) time: {end_time - start_time:.4f} seconds")
    # Cleanup the downloaded files
    import os
    for i in range(len(urls)):
        try:
            os.remove(f"file_async_{i}.html")
        except OSError:
            pass

# -----------------------------------------------------------------------------
# When to Use Which: Threading vs. concurrent.futures vs. asyncio
# -----------------------------------------------------------------------------
#
# | Feature             | Threading                                  | concurrent.futures                       | asyncio                                      |
# |---------------------|--------------------------------------------|--------------------------------------------|----------------------------------------------|
# | Concurrency Model   | Multiple threads within a single process    | Abstraction over threads and processes    | Single-threaded, event-loop-based concurrency |
# | GIL Impact          | Limited parallelism for CPU-bound tasks    | Uses processes for CPU-bound parallelism  | Not affected by GIL                         |
# | I/O-bound           | Good                                       | Good                                       | Excellent                                    |
# | CPU-bound           | Poor                                         | Good (with ProcessPoolExecutor)            | Poor                                         |
# | Complexity          | Relatively simple                          | Simpler than direct thread/process mgmt    | More complex, requires async programming    |
# | Use Cases           | I/O-bound tasks, simple concurrency         | Mixed I/O and CPU, simplified management  | High-concurrency I/O, modern async libraries |
#
# In more detail:
#
# -   Use **threading** when:
#     -   You have primarily I/O-bound tasks and need a relatively simple
#         way to achieve concurrency.
#     -   You are working with libraries that perform blocking I/O
#         operations.
#     -   You need to share data between concurrent tasks, and the overhead
#         of using processes is too high.  Remember to use appropriate
#         synchronization primitives (locks, etc.) to avoid race conditions.
#
# -   Use **concurrent.futures** when:
#     -   You want a high-level interface for managing both threads and
#         processes.
#     -   You have a mix of I/O-bound and CPU-bound tasks and want to
#         optimize performance by using threads for I/O and processes
#         for CPU.
#     -   You want to simplify the process of submitting tasks and
#         retrieving results.
#
# -   Use **asyncio** when:
#     -   You have highly concurrent I/O-bound tasks and need the best
#         possible performance and scalability.
#     -   You are working with modern asynchronous libraries (e.g.,
#         aiohttp, asyncpg) that are designed to work with `asyncio`.
#     -   You want to write non-blocking code that can handle a large
#         number of concurrent connections or requests within a single
#         thread.
#     -   You are building applications such as web servers, network
#         clients, or real-time communication systems.
#
# -----------------------------------------------------------------------------
# Main Execution
# -----------------------------------------------------------------------------
#
if __name__ == "__main__":
    print("Demonstrating Threading for I/O-bound tasks:")
    demonstrate_threading_io()
    print("\nDemonstrating concurrent.futures for mixed tasks:")
    demonstrate_concurrent_futures()
    print("\nDemonstrating asyncio for I/O-bound tasks:")
    try:
        asyncio.run(demonstrate_asyncio_io())
    except RuntimeError as e:
        if "asyncio.run() cannot be called from a running event loop" in str(e):
            print(f"RuntimeError: {e}")
            print("This error occurs because asyncio.run() was called within another asyncio context.")
            print("The example will still run, but this error might occur in more complex scenarios.")
            # In a real application, you would handle this more carefully, typically by
            # getting the running loop and calling the coroutine directly.
            #Here, we are not getting the loop to keep the example simple and focused
        else:
            raise  # Re-raise the error if it's a different one