# -*- coding: utf-8 -*-
"""Refactor Bloated Class with Generators and Composition

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18pY-kSWn5Liptb1ZiPrRHufVjJpYtf6W
"""

"""
Day 3, Session 1, Topic 5: Refactor a Bloated Class Using Generators and Composition

This file covers refactoring a bloated class using generators and composition
to improve code structure, readability, and maintainability.
"""

# 5. Refactor a Bloated Class Using Generators and Composition
# -----------------------------------------------------------
# Concept:
#    -   Bloated Class: A class that has too many responsibilities, methods,
#        or attributes, making it hard to understand, maintain, and test.
#    -   Composition:  A design principle where classes are composed of
#        instances of other classes, rather than inheriting from them
#        (favor composition over inheritance).
#    -   Generators: Can be used to simplify complex iteration logic within a class
#        and to decouple data processing from the class itself.
#
# Why is it important?
#    -   Readability:  Smaller, focused classes are easier to understand than
#        large, monolithic ones.
#    -   Maintainability:  Changes to one part of a system are less likely to
#        affect other parts when classes are decoupled.
#    -   Testability:  Smaller classes with single responsibilities are easier
#        to test in isolation.
#    -   Reusability:  Composed classes can be reused in different contexts.
#    -   Performance: Generators can improve performance by processing data lazily
#        and avoiding the creation of large intermediate lists.
#
# How to Refactor:
#    1. Identify Responsibilities:  Analyze the bloated class and identify its
#       distinct responsibilities.
#    2. Extract Classes:  Create new classes, each responsible for a single
#       responsibility.
#    3. Use Composition:  Compose the original class from instances of the
#       newly created classes.
#    4. Use Generators:  If the class has complex iteration logic, use
#       generators to simplify it and decouple data processing.
#
# Challenge:
#    You are given a `DataProcessor` class that reads data from a file,
#    processes it, and writes the results to another file.  The class
#    has grown over time and has become bloated with too many
#    responsibilities.  Refactor this class using generators and
#    composition to improve its design.
#
#    Here's the original bloated class:
#
# ```python
class DataProcessor:
    def __init__(self, input_file, output_file):
        self.input_file = input_file
        self.output_file = output_file

    def read_data(self):
        """Reads data from the input file."""
        with open(self.input_file, 'r') as f:
            return f.readlines()

    def process_data(self, data):
        """Processes the data (e.g., filters and transforms it)."""
        processed_data = []
        for line in data:
            if 'error' not in line.lower():  # filter out error lines
                parts = line.strip().split(',')
                if len(parts) > 1:
                    try:
                        value = float(parts[1])
                        processed_data.append(value * 2)  # double the value
                    except ValueError:
                        pass  # ignore lines with invalid numbers
        return processed_data

    def write_data(self, data):
        """Writes the processed data to the output file."""
        with open(self.output_file, 'w') as f:
            for value in data:
                f.write(str(value) + '\n')

    def run(self):
        """Runs the entire data processing pipeline."""
        data = self.read_data()
        processed_data = self.process_data(data)
        self.write_data(processed_data)
        print(f"Data processed and written to {self.output_file}")
#
# ```
#
#    Refactor this class into smaller, more focused classes and use generators
#    to handle the data processing.
#
# Solution:
# ```python
import time

class DataReader:
    """Reads data from a file."""
    def __init__(self, input_file):
        self.input_file = input_file

    def read_data(self):
        with open(self.input_file, 'r') as f:
            for line in f:  # Use a generator to read line by line.
                yield line

class DataProcessor:
    """Processes data (filters and transforms)."""
    def process_data(self, data_source):
        """Processes the data (e.g., filters and transforms it).
           Now takes a data source (any iterable) as input.
        """
        for line in data_source:
            if 'error' not in line.lower():
                parts = line.strip().split(',')
                if len(parts) > 1:
                    try:
                        value = float(parts[1])
                        yield value * 2  # Use a generator to yield processed data.
                    except ValueError:
                        pass

class DataWriter:
    """Writes data to a file."""
    def __init__(self, output_file):
        self.output_file = output_file

    def write_data(self, data_source):
        """Writes the processed data to the output file.
           Now takes a data source (any iterable) as input.
        """
        with open(self.output_file, 'w') as f:
            for value in data_source:
                f.write(str(value) + '\n')

class Pipeline:
    """Orchestrates the data processing pipeline."""
    def __init__(self, reader, processor, writer):
        self.reader = reader
        self.processor = processor
        self.writer = writer

    def run(self):
        """Runs the data processing pipeline."""
        data = self.reader.read_data()
        processed_data = self.processor.process_data(data)
        self.writer.write_data(processed_data)
        print(f"Data processed and written to {self.writer.output_file}")

def main():
    """Main function to run the pipeline."""
    input_file = 'input.txt'
    output_file = 'output.txt'

    # Create a dummy input file for testing
    with open(input_file, 'w') as f:
        f.write("valid,10\n")
        f.write("error,abc\n")
        f.write("valid,20\n")
        f.write("invalid,xyz\n")
        f.write("valid,30\n")

    reader = DataReader(input_file)
    processor = DataProcessor()
    writer = DataWriter(output_file)
    pipeline = Pipeline(reader, processor, writer)
    pipeline.run()



if __name__ == "__main__":
    main()
#
# ```
#
# Key improvements in the refactored code:
#
# -   Single Responsibility Principle: Each class has a single, well-defined
#     responsibility.
# -   Composition: The `Pipeline` class is composed of instances of the
#     `DataReader`, `DataProcessor`, and `DataWriter` classes.
# -   Generators: The `DataReader` and `DataProcessor` classes use generators
#     to process data lazily, which can improve performance and reduce memory
#     usage, especially for large files.
# -   Decoupling: The classes are decoupled, making them easier to test and reuse.
# -   Readability: The code is more modular and easier to understand.
#
# This refactored design is more flexible, maintainable, and testable than the
# original bloated class.